{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, the data from the NLSY79 are cleaned and processed for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I draw code for this notebook from https://github.com/HumanCapitalAnalysis/nlsy-data. These contributors maintain a cleaned version of the National Longitudinal Survey of Youth 1979 (NLSY79). A majority of the code below should be credited to the above linked contributors: Luis Wardenbach, Philipp Eisenhauer, Sebastian Becker, and @bekauf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shlex\n",
    "import pickle\n",
    "from numpy.testing import assert_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mappings():\n",
    "    \"\"\"Process a mapping of two separate cases: (1) variables that vary by year, and \n",
    "    (2) variables where there are multiple realizations each year. Start with 1978 \n",
    "    as information about 1978 employment histories is collected with the initial \n",
    "    interview. Note that from 1996 on, the NLSY is generated every other year. \n",
    "    \"\"\"\n",
    "    # Set up grid for survey years. \n",
    "    years = range(1978, 2018)\n",
    "\n",
    "    # Set up a dictionary for variables \n",
    "    dct_full = dict()\n",
    "\n",
    "    dct_full.update(process_time_constant(years))\n",
    "    dct_full.update(process_multiple_each_year())\n",
    "    dct_full.update(process_single_each_year())\n",
    "    dct_full.update(process_highest_degree_received())\n",
    "    dct_full.update(process_school_enrollment_monthly())\n",
    "\n",
    "    # Finishing\n",
    "    return years, dct_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(substrings):\n",
    "    \"\"\"Search through the variable descriptions in NLSY file by substrings. \n",
    "    \"\"\"\n",
    "    # Allow passing in a string or list of strings from the variable descriptions.\n",
    "    if type(substrings) == str:\n",
    "        substrings = [substrings]\n",
    "\n",
    "    with open(r'C:\\Users\\15853\\Desktop\\repos\\gorman-earlyjobskill-analysis\\data\\input\\full-list-variables.sdf', 'r') as infile:\n",
    "        for line in infile.readlines():\n",
    "            is_relevant = [substring in line for substring in substrings]\n",
    "            is_relevant = np.all(is_relevant)\n",
    "            if not is_relevant:\n",
    "                continue\n",
    "            # This special treatment is only required for the string that identifies RACE.\n",
    "            line = line.replace(\"'\", '')\n",
    "            list_ = shlex.split(line)\n",
    "            name = list_[0].replace('.', '')\n",
    "\n",
    "            return name\n",
    "\n",
    "    raise AssertionError('Substrings not found ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_name(substrings):\n",
    "    \"\"\"Search through the variable descriptions in NLSY file by substrings. \n",
    "    \"\"\"\n",
    "    # Allow passing in a string or list of strings from the variable descriptions.\n",
    "    if type(substrings) == str:\n",
    "        substrings = [substrings]\n",
    "\n",
    "    container = dict()\n",
    "    with open(r'C:\\Users\\15853\\Desktop\\repos\\gorman-earlyjobskill-analysis\\data\\input\\full-list-variables.sdf', 'r') as infile:\n",
    "        for line in infile.readlines():\n",
    "            is_relevant = [substring in line for substring in substrings]\n",
    "            is_relevant = np.all(is_relevant)\n",
    "            if is_relevant:\n",
    "                list_ = shlex.split(line)\n",
    "                name = list_[0].replace('.', '')\n",
    "                year = int(list_[1])\n",
    "                container[year] = name\n",
    "\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_time_constant(years):\n",
    "    \"\"\"Process time-constant variables.\n",
    "    \"\"\"    \n",
    "    dct_constant = dict()\n",
    "\n",
    "    dct_constant['RACE'] = dict()\n",
    "    substrings = 'RACIAL/ETHNIC COHORT FROM SCREENER'\n",
    "    for year in years:\n",
    "        dct_constant['RACE'][year] = get_name(substrings)\n",
    "\n",
    "    dct_constant['IDENTIFIER'] = dict()\n",
    "    substrings = 'CASEID'\n",
    "    for year in years:\n",
    "        dct_constant['IDENTIFIER'][year] = get_name(substrings)\n",
    "\n",
    "    dct_constant['SAMPLE_ID'] = dict()\n",
    "    substrings = 'SAMPLE_ID'\n",
    "    for year in years:\n",
    "        dct_constant['SAMPLE_ID'][year] = get_name(substrings)\n",
    "\n",
    "    dct_constant['GENDER'] = dict()\n",
    "    substrings = 'SEX OF R'\n",
    "    for year in years:\n",
    "        dct_constant['GENDER'][year] = get_name(substrings)\n",
    "\n",
    "    dct_constant['HIGHEST_GRADE_COMPLETED_FATHER'] = dict()\n",
    "    substrings = 'HGC-FATHER'\n",
    "    for year in years:\n",
    "        dct_constant['HIGHEST_GRADE_COMPLETED_FATHER'][year] = get_name(substrings)\n",
    "\n",
    "    dct_constant['HIGHEST_GRADE_COMPLETED_MOTHER'] = dict()\n",
    "    substrings = 'HGC-MOTHER'\n",
    "    for year in years:\n",
    "        dct_constant['HIGHEST_GRADE_COMPLETED_MOTHER'][year] = get_name(substrings)\n",
    "        \n",
    "    '''EMOTIONAL / APTITUDE / INTELLIGENCE SCORES \n",
    "    '''    \n",
    "    # ROTTER'S LOCUS OF CONTROL SCALE \n",
    "    dct_constant['ROTTER_SCORE'] = dict()\n",
    "    substrings = 'ROTTER SCALE SCORE'\n",
    "    for year in years:\n",
    "        dct_constant['ROTTER_SCORE'][year] = get_name(substrings)\n",
    "\n",
    "    for i in range(1, 5):\n",
    "        label = 'ROTTER_' + str(i)\n",
    "        substrings = 'ROTTER-' + str(i) + 'A'\n",
    "        dct_constant[label] = dict()\n",
    "        for year in years:\n",
    "            dct_constant[label][year] = get_name(substrings)\n",
    "            \n",
    "    # ROSENBERG SELF-ESTEEM SCORE \n",
    "    dct_constant['ROSENBERG_SCORE'] = dict()\n",
    "    substrings = 'SELF-ESTEEM SCORE'\n",
    "    for year in years:\n",
    "        dct_constant['ROSENBERG_SCORE'][year] = get_name(substrings)\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        label = 'ROSENBERG_' + str(i)\n",
    "        substrings = 'R030' + str(i + 34) + '.00'\n",
    "        dct_constant[label] = dict()\n",
    "        for year in years:\n",
    "            dct_constant[label][year] = get_name(substrings)\n",
    "\n",
    "    dct_constant['ASVAB_ARITHMETIC_REASONING'] = dict()\n",
    "    substrings = 'PROFILES, ASVAB VOCATIONAL TEST - SECTION 2-ARITHMETIC REASONING'\n",
    "    for year in years:\n",
    "        dct_constant['ASVAB_ARITHMETIC_REASONING'][year] = get_name(substrings)\n",
    "\n",
    "    dct_constant['ASVAB_WORD_KNOWLEDGE'] = dict()\n",
    "    substrings = 'PROFILES, ASVAB VOCATIONAL TEST - SECTION 3-WORD KNOWLEDGE'\n",
    "    for year in years:\n",
    "        dct_constant['ASVAB_WORD_KNOWLEDGE'][year] = get_name(substrings)\n",
    "\n",
    "    dct_constant['ASVAB_PARAGRAPH_COMPREHENSION'] = dict()\n",
    "    substrings = 'PROFILES, ASVAB VOCATIONAL TEST - SECTION 4-PARAGRAPH COMP'\n",
    "    for year in years:\n",
    "        dct_constant['ASVAB_PARAGRAPH_COMPREHENSION'][year] = get_name(substrings)\n",
    "\n",
    "    dct_constant['ASVAB_NUMERICAL_OPERATIONS'] = dict()\n",
    "    substrings = 'PROFILES, ASVAB VOCATIONAL TEST - SECTION 5-NUMERICAL OPERATIONS'\n",
    "    for year in years:\n",
    "        dct_constant['ASVAB_NUMERICAL_OPERATIONS'][year] = get_name(substrings)\n",
    "\n",
    "    dct_constant['ASVAB_ALTERED_TESTING'] = dict()\n",
    "    substrings = 'PROFILES, ASVAB VOCATIONAL TEST - NORMAL/ALTERED TESTING'\n",
    "    for year in years:\n",
    "        dct_constant['ASVAB_ALTERED_TESTING'][year] = get_name(substrings)\n",
    "\n",
    "    dct_constant['AFQT_1'] = dict()\n",
    "    substrings = 'PROFILES, ARMED FORCES QUALIFICATION TEST (AFQT) PERCENTILE SCORE - 1980'\n",
    "    for year in years:\n",
    "        dct_constant['AFQT_1'][year] = get_name(substrings)\n",
    "\n",
    "    return dct_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multiple_each_year():\n",
    "    \"\"\"Process variables with multiple each year--\n",
    "    specifically, employment status for multiple weeks.\n",
    "    \"\"\"\n",
    "    dct_multiple = dict()\n",
    "\n",
    "    # The mapping between the continuous weeks counter and the calendar year is provided on the\n",
    "    # NLSY website.\n",
    "    mapping_continuous_week = pd.read_pickle(r'C:\\Users\\15853\\Desktop\\repos\\gorman-earlyjobskill-analysis\\data\\input\\continuous_week_crosswalk_2012.pkl')\n",
    "    years = mapping_continuous_week['Week Start: \\nYear'].unique()\n",
    "\n",
    "    # Prepare container\n",
    "    year_weeks = dict()\n",
    "    for year in years:\n",
    "        year_weeks[year] = []\n",
    "\n",
    "    for index, row in mapping_continuous_week.iterrows():\n",
    "        year = row['Week Start: \\nYear']\n",
    "        year_weeks[year] += [row['Continuous \\nWeek Number']]\n",
    "\n",
    "    # Process employment information for some selected weeks.\n",
    "    weeks = [1, 7, 13, 14, 20, 26, 40, 46, 52]\n",
    "\n",
    "    for type_ in ['STATUS', 'HOURS']:\n",
    "        for week in weeks:\n",
    "            label, idx = 'EMP_' + type_ + '_WK_' + str(week), week - 1\n",
    "            dct_multiple[label] = dict()\n",
    "            for year in years:\n",
    "                substring = 'WEEK ' + str(year_weeks[year][idx])\n",
    "                if type_ == 'STATUS':\n",
    "                    substrings = ['LABOR FORCE STATUS', substring]\n",
    "                elif type_ == 'HOURS':\n",
    "                    substrings = ['HOURS AT ALL JOBS', substring]\n",
    "                else:\n",
    "                    raise AssertionError\n",
    "                dct_multiple[label][year] = get_name(substrings)\n",
    "\n",
    "    return dct_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_each_year():\n",
    "    \"\"\"Process variables that vary by year (i.e. one variable measured each year).\n",
    "    \"\"\"\n",
    "    # Initialize containers\n",
    "    dct = dict()\n",
    "\n",
    "    \n",
    "    ''' EDUCATION\n",
    "    '''\n",
    "    substrings = 'HIGHEST GRADE ATTENDED'\n",
    "    dct['HIGHEST_GRADE_ATTENDED'] = get_year_name(substrings)\n",
    "\n",
    "    substrings = 'HIGHEST GRADE COMPLETED AS'\n",
    "    dct['HIGHEST_GRADE_COMPLETED'] = get_year_name(substrings)\n",
    "    \n",
    "\n",
    "    ''' MONTH/YEAR OF BIRTH\n",
    "    '''\n",
    "    substrings = 'DATE OF BIRTH - YEAR'\n",
    "    dct['YEAR_OF_BIRTH'] = get_year_name(substrings)\n",
    "\n",
    "    substrings = 'DATE OF BIRTH - MONTH'\n",
    "    dct['MONTH_OF_BIRTH'] = get_year_name(substrings)\n",
    "    \n",
    "\n",
    "    ''' OCCUPATION INFORMATION \n",
    "    '''\n",
    "    # CPSOCC70\n",
    "    substrings = 'OCCUPATION AT CURRENT JOB/MOST RECENT JOB (70 CENSUS 3 DIGIT)'\n",
    "    dct['CPSOCC70'] = get_year_name(substrings)\n",
    "\n",
    "    # OCCALL70\n",
    "    for i in range(1, 6):\n",
    "        substrings = ['OCCUPATION (CENSUS 3 DIGIT, 70 CODES)', 'JOB #0' + str(i)]\n",
    "        dct['OCCALL70_JOB_' + str(i)] = get_year_name(substrings)\n",
    "\n",
    "    # In the year 1993, the substring is changed for some reason and cannot be easily\n",
    "    # distinguished from the CPSOCC70 variable.\n",
    "    for i in range(2, 6):\n",
    "        substrings = 'OCCUPATION (CENSUS 3 DIGIT) JOB #0' + str(i)\n",
    "        dct['OCCALL70_JOB_' + str(i)].update(get_year_name(substrings))\n",
    "\n",
    "    # In the year 1982, the substring for the fourth job contains a 0 instead of an O.\n",
    "    substrings = ['OCCUPATION (CENSUS 3 DIGIT, 70 C0DES)', 'JOB #04']\n",
    "    dct['OCCALL70_JOB_4'].update(get_year_name(substrings))\n",
    "\n",
    "    #LINKING OCALLEMP70 and CPSOCC7\n",
    "    for i in range(1, 6):\n",
    "        substrings = ['IS JOB #0' + str(i) + ' SAME AS CURRENT JOB?']\n",
    "        dct['CPS_JOB_INDICATOR_JOB_' + str(i)] = get_year_name(substrings)\n",
    "        \n",
    "\n",
    "    '''INCOME AND WAGES \n",
    "    '''\n",
    "    # HOURLY RATE OF PAY JOB ##\n",
    "    for i in range(1, 6):\n",
    "        substrings = 'HOURLY RATE OF PAY JOB #0' + str(i)\n",
    "        dct['WAGE_HOURLY_JOB_' + str(i)] = get_year_name(substrings)\n",
    "\n",
    "    # TOTAL INCOME FROM MILITARY SERVICE\n",
    "    substrings = 'TOTAL INCOME FROM MILITARY SERVICE'\n",
    "    dct['INCOME_MILITARY'] = get_year_name(substrings)\n",
    "    \n",
    "    # TOTAL INCOME FROM WAGES AND SALARY \n",
    "    substrings = 'TOTAL INCOME FROM WAGES AND SALARY'\n",
    "    dct['INCOME_WAGES_SALARY'] = get_year_name(substrings)\n",
    "    \n",
    "    #POVERTY STATUS \n",
    "    substrings = 'FAMILY POVERTY STATUS IN PREVIOUS CALENDAR YEAR'\n",
    "    dct['POVSTATUS'] = get_year_name(substrings)\n",
    "    \n",
    "    \n",
    "    '''HEALTH VARIABLES \n",
    "    '''\n",
    "    substrings = 'DOES HEALTH LIMIT KIND OF WORK R CAN DO?'\n",
    "    dct['AMT_WORK_LMT'] = get_year_name(substrings)\n",
    "    \n",
    "    substrings = 'DOES HEALTH LIMIT KIND OF WORK R CAN DO?'\n",
    "    dct['TYPE_WORK_LMT'] = get_year_name(substrings)\n",
    "\n",
    "    substrings = 'R COVERED BY ANY HEALTH/HOSPITAL PLAN'\n",
    "    dct['HEALTH_INS'] = get_year_name(substrings)\n",
    "    \n",
    "        \n",
    "    ''' OTHER VARIABLES\n",
    "    '''\n",
    "    # MARITAL STATUS \n",
    "    substrings = 'MARITIAL STATUS'\n",
    "    dct['MAR_STATUS'] = get_year_name(substrings)\n",
    "    \n",
    "    # REGION OF RESIDENCE\n",
    "    substrings = 'REGION OF CURRENT RESIDENCE'\n",
    "    dct['REGION'] = get_year_name(substrings) \n",
    "    \n",
    "    # REASON FOR NONINTERVIEW\n",
    "    substrings = ['REASON FOR NONINTERVIEW']\n",
    "    dct['REASON_NONINTERVIEW'] = get_year_name(substrings)\n",
    "    \n",
    "    # MILITARY ENROLLMENT STATUS AS OF MAY 1 SURVEY YEAR (REVISED)\n",
    "    substrings = 'ENROLLMENT STATUS AS OF MAY 1 SURVEY YEAR (REVISED)'\n",
    "    dct['ENROLLMENT_STATUS'] = get_year_name(substrings)\n",
    "\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function processes information on the highest degree ever received. There are\n",
    "# two different variables in some years with the same information.\n",
    "def process_highest_degree_received():\n",
    "\n",
    "    # This method reads in the variable names for the highest grade received.\n",
    "    def read_highest_degree_received():\n",
    "        \n",
    "        rslt = dict()\n",
    "        with open(r'C:\\Users\\15853\\Desktop\\repos\\gorman-earlyjobskill-analysis\\data\\input\\full-list-variables.sdf', 'r') as infile:\n",
    "            for line in infile.readlines():\n",
    "                is_relevant = 'HIGHEST DEGREE EVER RECEIVED' in line\n",
    "\n",
    "                if not is_relevant:\n",
    "                    continue\n",
    "\n",
    "                list_ = shlex.split(line)\n",
    "                variable, year = list_[0].replace('.', ''), int(list_[1])\n",
    "                if year not in rslt.keys():\n",
    "                    rslt[year] = []\n",
    "\n",
    "                rslt[year] += [variable]\n",
    "\n",
    "        return rslt\n",
    "\n",
    "    rslt = read_highest_degree_received()\n",
    "\n",
    "    dct = dict()\n",
    "    for year in rslt.keys():\n",
    "        for val in rslt[year]:\n",
    "            label = 'HIGHEST_DEGREE_RECEIVED_1'\n",
    "            if label in dct.keys():\n",
    "                if year in dct[label].keys():\n",
    "                    label = 'HIGHEST_DEGREE_RECEIVED_2'\n",
    "            if label not in dct.keys():\n",
    "                dct[label] = dict()\n",
    "            dct[label][year] = val\n",
    "\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function processes the monthly school enrollment data. This is surprisingly\n",
    "# difficult as, for example, information about March 1990 is asked in the 1990 and 1991 surveys.\n",
    "def process_school_enrollment_monthly():\n",
    "\n",
    "    # Search for the information in the short description file.  \n",
    "    def read_school_enrollment_monthly():\n",
    "\n",
    "        rslt = dict()\n",
    "        with open(r'C:\\Users\\15853\\Desktop\\repos\\gorman-earlyjobskill-analysis\\data\\input\\full-list-variables.sdf', 'r') as infile:\n",
    "            for line in infile.readlines():\n",
    "                is_relevant = 'MONTHS ENROLLED IN SCHOOL SINCE LAST INT' in line\n",
    "                is_relevant = np.all(is_relevant)\n",
    "\n",
    "                if not is_relevant:\n",
    "                    continue\n",
    "\n",
    "                list_ = shlex.split(line)\n",
    "\n",
    "                # Collect information\n",
    "                variable, month = list_[0].replace('.', ''), list_[10]\n",
    "\n",
    "                if 'R09052.00' in line:\n",
    "                    month, year = list_[12], int(list_[13])\n",
    "               \n",
    "                # There are some typos in the variable descriptions\n",
    "                elif 'INT-' in line:\n",
    "                    month, year = list_[9], int(list_[10])\n",
    "                else:\n",
    "                    year = int(list_[11])\n",
    "\n",
    "                # The labeling convention for year is all over the place. For example 2012\n",
    "                # shows up as 12 as well.\n",
    "                if 0 <= year < 25:\n",
    "                    year += 2000\n",
    "                elif 70 < year < 100:\n",
    "                    year += 1900\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                # The labeling convention for the month is also inconsistent.\n",
    "                if 'JAN' in month:\n",
    "                    month = 'JANUARY'\n",
    "                elif 'FEB' in month:\n",
    "                    month = 'FEBRUARY'\n",
    "                elif 'MAR' in month:\n",
    "                    month = 'MARCH'\n",
    "                elif 'APR' in month:\n",
    "                    month = 'APRIL'\n",
    "                elif 'MAY' in month:\n",
    "                    month = 'MAY'\n",
    "                elif 'JUN' in month:\n",
    "                    month = 'JUNE'\n",
    "                elif 'JUL' in month:\n",
    "                    month = 'JULY'\n",
    "                elif 'AUG' in month:\n",
    "                    month = 'AUGUST'\n",
    "                elif 'SEP' in month:\n",
    "                    month = 'SEPTEMBER'\n",
    "                elif 'OCT' in month:\n",
    "                    month = 'OCTOBER'\n",
    "                elif 'NOV' in month:\n",
    "                    month = 'NOVEMBER'\n",
    "                elif 'DEC' in month:\n",
    "                    month = 'DECEMBER'\n",
    "                else:\n",
    "                    raise AssertionError\n",
    "\n",
    "                if year not in rslt.keys():\n",
    "                    rslt[year] = dict()\n",
    "                if month not in rslt[year].keys():\n",
    "                    rslt[year][month] = []\n",
    "\n",
    "                rslt[year][month] += [variable]\n",
    "\n",
    "        return rslt\n",
    "\n",
    "    rslt = read_school_enrollment_monthly()\n",
    "    dct = dict()\n",
    "    for year in rslt.keys():\n",
    "        for month in rslt[year].keys():\n",
    "            for val in rslt[year][month]:\n",
    "                label = 'ENROLLED_SCHOOL_' + month + '_1'\n",
    "\n",
    "                if label in dct.keys():\n",
    "                    if year in dct[label].keys():\n",
    "                        label = 'ENROLLED_SCHOOL_' + month + '_2'\n",
    "\n",
    "                if label not in dct.keys():\n",
    "                    dct[label] = dict()\n",
    "\n",
    "                dct[label][year] = val\n",
    "\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section contains some functionality for special treatment that is required for a\n",
    "selected few variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_highest_degree_received(df):\n",
    "    \"\"\" This function merges the information about the highest degree ever received,\n",
    "     sometimes collected under two variable names but never with conflicting information.\n",
    "     At least one of the two variables is always a missing value.\n",
    "    \"\"\"    \n",
    "    label = 'HIGHEST_DEGREE_RECEIVED'\n",
    "\n",
    "    # This assignment rule simply takes the first assignment and then tries to replace it with\n",
    "    # the second if the first is a missing value.\n",
    "    df[label] = df['HIGHEST_DEGREE_RECEIVED_1']\n",
    "\n",
    "    cond = df[label].isnull()\n",
    "    df.loc[cond, label] = df['HIGHEST_DEGREE_RECEIVED_2']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_highest_grade_attended(df):\n",
    "    \"\"\" The variable for highest grade attended contains a value 95 \n",
    "    which corresponds to UNGRADED.\n",
    "    \"\"\"\n",
    "    cond = df['HIGHEST_GRADE_ATTENDED'] == 95\n",
    "    df.loc[cond, 'HIGHEST_GRADE_ATTENDED'] = np.nan\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_school_enrollment_monthly(df):\n",
    "    \"\"\" This function merges information about monthly school enrollment, sometimes\n",
    "     collected twice due the differing time an individual is interviewed that year.\n",
    "    \"\"\"\n",
    "    months = []\n",
    "    months += ['JANUARY', 'FEBRUARY', 'MARCH', 'APRIL', 'MAY', 'JUNE', 'JULY', 'AUGUST']\n",
    "    months += ['SEPTEMBER', 'OCTOBER', 'NOVEMBER', 'DECEMBER']\n",
    "\n",
    "    for month in months:\n",
    "        label = 'ENROLLED_SCHOOL_' + month\n",
    "        df[label] = np.nan\n",
    "\n",
    "        df[label] = df['ENROLLED_SCHOOL_' + month + '_1']\n",
    "\n",
    "        cond = df[label].isnull()\n",
    "        df.loc[cond, label] = df['ENROLLED_SCHOOL_' + month + '_2']\n",
    "\n",
    "        # It also appears that sometimes the indicator that an individual was attending school that\n",
    "        # month takes values different from one. However, SELECTED is always positive and NOT\n",
    "        # SELECTED is always zero.\n",
    "        cond = df[label] == 0\n",
    "        df.loc[cond, label] = 0\n",
    "\n",
    "        cond = df[label] > 0\n",
    "        df.loc[cond, label] = 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_is_interviewed(df):\n",
    "    \"\"\"This function creates an indicator that evaluates to TRUE if an individual\n",
    "    was interviewed that year based on the information about the reasons for non-interviews. \n",
    "    \"\"\"\n",
    "    df['IS_INTERVIEWED'] = df['REASON_NONINTERVIEW'].fillna(0) == 0\n",
    "\n",
    "    for year in [1995, 1997, 1999, 2001, 2003, 2005, 2007, 2009, 2011]:\n",
    "        df.loc[(slice(None), year), 'IS_INTERVIEWED'] = False\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_employer_information(df):\n",
    "    \"\"\"This function merges the employer-specific information on an individual's occupation\n",
    "    using the 70 CPS codes into a new variable. See additional information at:\n",
    "    https://www.nlsinfo.org/content/cohorts/nlsy79/topical-guide/employment/jobs-employers\n",
    "    \"\"\"\n",
    "    # Create a set of new variables to signal to users that a modification took place.\n",
    "    for i in range(1, 6):\n",
    "        df['OCCALL70_MOD_JOB_' + str(i)] = df['OCCALL70_JOB_' + str(i)]\n",
    "\n",
    "    # The information on #1 is missing in 1979 and 1993, as it is identical with CPSOCC70.\n",
    "    for year in [1979, 1993]:\n",
    "        cond = df['SURVEY_YEAR'] == year\n",
    "        df.loc[cond, 'OCCALL70_MOD_JOB_1'] = df.loc[cond, 'CPSOCC70']\n",
    "\n",
    "    # For the years 1980 - 1992 there is an indicator variable that maps the CPSOCC70 information\n",
    "    # to the OCCALL70 variable.\n",
    "\n",
    "    # NOTE: There are two open questions that are ignored here: (1) There exist two variables in\n",
    "    # 1990 that read ``INT CHECK - IS JOB #01 SAME AS CURRENT JOB?'' (R3340000, R3342400). The\n",
    "    # realizations of both variables are not identical. (2) There exist a few individuals where\n",
    "    # the CPSOCC indicator takes value one for more than one of the 5 OCCALL70 variables. \n",
    "    for i in range(1, 6):\n",
    "        cond = (df['CPS_JOB_INDICATOR_JOB_' + str(i)] == 1)\n",
    "        df.loc[cond, 'OCCALL70_MOD_JOB_' + str(i)] = df.loc[cond, 'CPSOCC70']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_afqt_scores(df):\n",
    "    \"\"\"This function calculates the Aptitude, Achievement, and Intelligence (AFQT) scores, \n",
    "    with the Numerical Operations score adjusted along the lines described in NLS Attachment 106. \n",
    "    For more details, see information at: \n",
    "    https://www.nlsinfo.org/content/cohorts/nlsy79/topical-guide/education/aptitude-achievement-intelligence-scores\n",
    "    \"\"\"\n",
    "    df['NUMERICAL_ADJ'] = df['ASVAB_NUMERICAL_OPERATIONS']\n",
    "\n",
    "    adjust_no = {0: 0, 1: 0, 2: 1, 3: 2, 7: 8, 8: 9, 9: 10, 10: 11, 11: 12, 12: 14, 13: 15, 14: 16,\n",
    "        15: 17, 16: 18, 17: 19, 18: 21, 19: 22, 20: 23, 21: 24, 22: 25, 23: 26, 24: 27, 25: 28,\n",
    "        26: 29, 27: 30, 28: 31, 29: 33, 30: 34, 31: 35, 32: 36, 33: 37, 34: 38, 35: 39, 36: 39,\n",
    "        37: 40, 38: 41, 39: 42, 40: 43, 41: 44, 42: 45, 43: 46, 44: 47, 45: 48, 46: 49, 47: 49,\n",
    "        48: 50, 49: 50, 50: 50}\n",
    "\n",
    "    df['NUMERICAL_ADJ'].replace(adjust_no, inplace=True)\n",
    "\n",
    "    df['AFQT_RAW'] = 0.00\n",
    "    df['AFQT_RAW'] += df['ASVAB_ARITHMETIC_REASONING']\n",
    "    df['AFQT_RAW'] += df['ASVAB_WORD_KNOWLEDGE']\n",
    "    df['AFQT_RAW'] += df['ASVAB_PARAGRAPH_COMPREHENSION']\n",
    "    df['AFQT_RAW'] += 0.5 * df['NUMERICAL_ADJ']\n",
    "\n",
    "    del df['NUMERICAL_ADJ']\n",
    "    \n",
    "    # There are a few variables which can be used to compute AFQT_RAW while there is no AFQT_1\n",
    "    # available. The variable AFQT_1 is set to NAN by the NLSY team if the test procedure was\n",
    "    # altered, i.e. variable R06148 (ASVAB_ALTERED_TESTING) takes value 67. However, those who maintain\n",
    "    # the cleaned version of this dataset noticed there are other indicators of problems as well.\n",
    "    #\n",
    "    #   PROFILES, ASVAB VOCATIONAL TEST - NORMAL/ALTERED TESTING\n",
    "    #\n",
    "    #       11625   51      COMPLETED\n",
    "    #          41   52      COMP-CONVERTED REFUSAL\n",
    "    #         127   53      COMP-PROBLEM REPORTED\n",
    "    #          85   54      COMP-SPANISH INSTR. CARDS\n",
    "    #          36   67      COMP-PRODECURES ALTERED\n",
    "    #\n",
    "    # They followed up with the NLSY staff for guidance on how to deal with 51, 52, 53,\n",
    "    # 54. The correspondence is available in ``correspondence-altered-testing.pdf'' in the sources\n",
    "    # subdirectory of their github page. In short, detailed info isn't available anymore on the \n",
    "    # meaning of the different realizations. They follow the original decision of the NLSY staff\n",
    "    # to only set 67 to NAN.\n",
    "    cond = df['ASVAB_ALTERED_TESTING'].isin([67])\n",
    "    df.loc[cond, 'AFQT_RAW'] = np.nan\n",
    "\n",
    "    # This unit test reconstructs the AFQT_1 variable from the inputs.\n",
    "    assert_equal(_test_afqt(df), True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_birth_information(df):\n",
    "    \"\"\" This function aggregates the birth information collected in 1979 and 1981. For more\n",
    "    details, see information at:\n",
    "    https://www.nlsinfo.org/content/cohorts/nlsy79/topical-guide/household/age\n",
    "    \"\"\"\n",
    "    # This method constructs the correct birth variable for each agent.\n",
    "    def _construct_birth_info(agent):\n",
    "\n",
    "        # Store the original information for now for debugging and testing purposes.\n",
    "        for substring in ['YEAR_OF_BIRTH', 'MONTH_OF_BIRTH']:\n",
    "            for year in [1979, 1981]:\n",
    "                agent[substring + '_' + str(year)] = agent[substring][:, year].values[0]\n",
    "            # Start with a clean slate that always prefers the information from 1981\n",
    "            agent[substring] = np.nan\n",
    "            agent[substring] = agent[substring + '_1981']\n",
    "            # If no information in 1981 is available, fall back to 1979.\n",
    "            if agent[substring].isnull().values.any():\n",
    "                agent[substring] = agent[substring + '_1979']\n",
    "\n",
    "        return agent\n",
    "\n",
    "    df = df.groupby('IDENTIFIER').apply(_construct_birth_info)\n",
    "\n",
    "    # Apply some basic tests to ensure that the computation was correct.\n",
    "    for substring in ['YEAR_OF_BIRTH', 'MONTH_OF_BIRTH']:\n",
    "        # There cannot be any missing values in the birth variables.\n",
    "        assert not df[substring].isnull().any()\n",
    "        # Whenever there is not a missing value in for 1981 then the columns should be identical.\n",
    "        # For the others it should be identical to 1979.\n",
    "        cond = (df[substring + '_1981'].notnull())\n",
    "        assert df.loc[cond, substring].equals(df.loc[cond, substring + '_1981'])\n",
    "        assert df.loc[~cond, substring].equals(df.loc[~cond, substring + '_1979'])\n",
    "\n",
    "    # There's no need to keep track of the intermediate variables.\n",
    "    for substring in ['YEAR_OF_BIRTH', 'MONTH_OF_BIRTH']:\n",
    "        for year in [1979, 1981]:\n",
    "            del df[substring + '_' + str(year)]\n",
    "\n",
    "    df['YEAR_OF_BIRTH'] += 1900\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_afqt(df):\n",
    "    \"\"\" NLSY provides percentile information for AFQT scores, reconstructed here \n",
    "    as a check based on NLSY instructions.\n",
    "    \"\"\"\n",
    "    # Breaking the logic of the code a bit, only work with copies of the object here.\n",
    "    df_internal = df.copy(deep=True)\n",
    "\n",
    "    # Adjust for missing values, even though this is done later in the code for all variables.\n",
    "    for label in ['AFQT_RAW', 'AFQT_1']:\n",
    "        cond = (df_internal[label] < 0)\n",
    "        df_internal.loc[cond, label] = np.nan\n",
    "\n",
    "    # Match ``AFQT_RAW`` to percentile of distribution\n",
    "    cond = df_internal['AFQT_RAW'] <= 23.5\n",
    "    df_internal.loc[cond, 'AFQT_PERCENTILES'] = 1\n",
    "\n",
    "    infos = []\n",
    "    infos += [(23.50, 27.00, 2), (27.00, 29.50, 3), (29.50, 32.00, 4), (32.00, 34.00, 5)]\n",
    "    infos += [(34.00, 36.50, 6), (36.50, 38.00, 7), (38.00, 40.00, 8), (40.00, 41.00, 9)]\n",
    "\n",
    "    infos += [(41.00, 42.50, 10), (42.50, 44.00, 11), (44.00, 45.50, 12), (45.50, 47.00, 13)]\n",
    "    infos += [(47.00, 48.50, 14), (48.50, 49.50, 15), (49.50, 51.00, 16), (51.00, 52.50, 17)]\n",
    "\n",
    "    for i in range(18, 29):\n",
    "        infos += [(i + 34.50, i + 35.50, i)]\n",
    "\n",
    "    infos += [(63.50, 64.00, 29), (64.00, 65.00, 30), (65.00, 65.50, 31), (65.50, 66.50, 32)]\n",
    "    infos += [(66.50, 67.00, 33), (67.00, 67.50, 34), (67.50, 68.50, 35), (68.50, 69.00, 36)]\n",
    "    infos += [(69.00, 69.50, 37), (69.50, 70.50, 38), (70.50, 71.00, 39), (71.00, 71.50, 40)]\n",
    "    infos += [(71.50, 72.00, 41), (72.00, 73.00, 42), (73.00, 73.50, 43), (73.50, 74.00, 44)]\n",
    "    infos += [(74.00, 74.50, 45), (74.50, 75.50, 46), (75.50, 76.00, 47), (76.00, 76.50, 48)]\n",
    "    infos += [(76.50, 77.50, 49)]\n",
    "\n",
    "    for i, j in enumerate(range(50, 62), 1):\n",
    "        infos += [(j + 28.00 - 0.50 * i, j + 28.00, j)]\n",
    "\n",
    "    for i, j in enumerate(range(62, 94), 1):\n",
    "        infos += [(j + 21.50 - 0.50 * i,  j + 21.50, j)]\n",
    "\n",
    "    infos += [(99.00, 100.00, 94)]\n",
    "\n",
    "    for i, j in enumerate(range(95, 98), 1):\n",
    "        infos += [(j + 5.50 - 0.50 * i, j + 5.50, j)]\n",
    "\n",
    "    infos += [(101.50, 102.50, 98), (102.5, 105.00, 99)]\n",
    "\n",
    "    for info in infos:\n",
    "        lower, upper, value = info\n",
    "        cond = (df_internal['AFQT_RAW'] > lower) & (df_internal['AFQT_RAW'] <= upper)\n",
    "        df_internal.loc[cond, 'AFQT_PERCENTILES'] = value\n",
    "\n",
    "    return df_internal['AFQT_PERCENTILES'].equals(df_internal['AFQT_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this model is a maintained list of all variables processed for the panel and checked via testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This maintained list contains all variables processed for the panel. \n",
    "TIME_CONSTANT = []\n",
    "TIME_CONSTANT += ['IDENTIFIER', 'RACE', 'GENDER']\n",
    "TIME_CONSTANT += ['ASVAB_ARITHMETIC_REASONING', 'ASVAB_WORD_KNOWLEDGE', 'ASVAB_ALTERED_TESTING']\n",
    "TIME_CONSTANT += ['ASVAB_PARAGRAPH_COMPREHENSION', 'ASVAB_NUMERICAL_OPERATIONS']\n",
    "TIME_CONSTANT += ['AFQT_1', 'SAMPLE_ID', 'ROTTER_SCORE', 'ROTTER_1', 'ROTTER_2']\n",
    "TIME_CONSTANT += ['ROTTER_3', 'ROTTER_4', 'ROSENBERG_SCORE', 'ROSENBERG_1', 'ROSENBERG_2']\n",
    "TIME_CONSTANT += ['ROSENBERG_3', 'ROSENBERG_4', 'ROSENBERG_5', 'ROSENBERG_6', 'ROSENBERG_7']\n",
    "TIME_CONSTANT += ['ROSENBERG_8', 'ROSENBERG_9', 'ROSENBERG_10']\n",
    "TIME_CONSTANT += ['HIGHEST_GRADE_COMPLETED_FATHER', 'HIGHEST_GRADE_COMPLETED_MOTHER']\n",
    "\n",
    "TIME_VARYING = []\n",
    "TIME_VARYING += ['ENROLLMENT_STATUS', 'YEAR_OF_BIRTH', 'CPSOCC70']\n",
    "TIME_VARYING += ['MONTH_OF_BIRTH', 'HIGHEST_GRADE_COMPLETED', 'SURVEY_YEAR']\n",
    "TIME_VARYING += ['INCOME_MILITARY', 'REASON_NONINTERVIEW', 'HIGHEST_GRADE_ATTENDED']\n",
    "TIME_VARYING += ['HIGHEST_DEGREE_RECEIVED_1', 'HIGHEST_DEGREE_RECEIVED_2']\n",
    "TIME_VARYING += ['INCOME_WAGES_SALARY', 'POVSTATUS', 'AMT_WORK_LMT']\n",
    "TIME_VARYING += ['TYPE_WORK_LMT','HEALTH_INS', 'MAR_STATUS', 'REGION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start in ['EMP_HOURS_WK_', 'EMP_STATUS_WK_']:\n",
    "    for week in ['1', '7', '13', '14', '20', '26', '40', '46', '52']:\n",
    "        TIME_VARYING += [start + week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start in ['WAGE_HOURLY_JOB_', 'CPS_JOB_INDICATOR_JOB_', 'OCCALL70_JOB_']:\n",
    "    for job in ['1', '2', '3', '4', '5']:\n",
    "        TIME_VARYING += [start + job]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = []\n",
    "months += ['JANUARY', 'FEBRUARY', 'MARCH', 'APRIL', 'MAY', 'JUNE', 'JULY', 'AUGUST', 'SEPTEMBER']\n",
    "months += ['OCTOBER', 'NOVEMBER', 'DECEMBER']\n",
    "for month in months:\n",
    "    for idx in ['1', '2']:\n",
    "        TIME_VARYING += ['ENROLLED_SCHOOL_' + month + '_' + idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These variables are created during processing. These are part of a separate list as they are\n",
    "# not available when the data is transformed from wide to long format.\n",
    "DERIVED_VARS = []\n",
    "DERIVED_VARS += ['AFQT_RAW', 'IS_INTERVIEWED', 'HIGHEST_DEGREE_RECEIVED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start in ['OCCALL70_MOD_JOB_']:\n",
    "    for job in ['1', '2', '3', '4', '5']:\n",
    "        DERIVED_VARS += [start + job]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in months:\n",
    "    DERIVED_VARS += ['ENROLLED_SCHOOL_' + month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceCls(object):\n",
    "    \"\"\"This class contains all methods that prepare the source dataset for further uses.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Class attributes\n",
    "        self.survey_years = None\n",
    "        self.source_wide = None\n",
    "        self.source_long = None\n",
    "        self.dct = None\n",
    "    \n",
    "    def read_source(self, num_agents=None):\n",
    "        \"\"\"Read the original file from the NLS Investigator\n",
    "        \"\"\"\n",
    "        self.source_wide = pd.read_csv(r'C:\\Users\\15853\\Desktop\\repos\\gorman-earlyjobskill-analysis\\data\\input\\full-list-variables.csv', nrows=num_agents)\n",
    "\n",
    "        # Process variable dictionary\n",
    "        survey_years, dct = get_mappings()\n",
    "\n",
    "        # Attach results as class attributes\n",
    "        self.survey_years = survey_years\n",
    "        self.dct = dct\n",
    "\n",
    "    # Add some basic variables that are easily constructed from the original information\n",
    "    # and frequently used during finer processing of the data.\n",
    "    def add_basic_variables(self):\n",
    "\n",
    "        # Distribute class attributes\n",
    "        source_long = self.source_long\n",
    "\n",
    "        # Processing birth information is not as straightforward as one might think.\n",
    "        source_long = aggregate_birth_information(source_long)\n",
    "\n",
    "        # Compute the AFQT score as suggested in the data documentation.\n",
    "        source_long = calculate_afqt_scores(source_long)\n",
    "\n",
    "        # There are no missing values for all these variables, so integer type can be enforced.\n",
    "        for varname in ['MONTH_OF_BIRTH', 'YEAR_OF_BIRTH']:\n",
    "            source_long[varname] = source_long[varname].astype('int64')\n",
    "\n",
    "        source_long = aggregate_school_enrollment_monthly(source_long)\n",
    "        source_long = aggregate_highest_degree_received(source_long)\n",
    "        source_long = cleaning_highest_grade_attended(source_long)\n",
    "        source_long = standarize_employer_information(source_long)\n",
    "        source_long = create_is_interviewed(source_long)\n",
    "\n",
    "        self.source_long = source_long\n",
    "\n",
    "    # Transform from wide to long format.    \n",
    "    def transform_wide_to_panel(self):\n",
    "\n",
    "        # Distribute class attributes\n",
    "        survey_years = self.survey_years\n",
    "        source_wide = self.source_wide\n",
    "        dct = self.dct\n",
    "\n",
    "        # Change from the original wide format to the typical panel structure\n",
    "        self.source_long = wide_to_long(source_wide, survey_years, dct)\n",
    "        self._set_missing_values()\n",
    "\n",
    "    # Ensure a uniform treatment of missing values.    \n",
    "    def _set_missing_values(self):\n",
    " \n",
    "        # Distribute class attributes\n",
    "        source_long = self.source_long\n",
    "\n",
    "        # In the original dataset, missing values are indicated by negative values\n",
    "        for varname in TIME_VARYING + TIME_CONSTANT:\n",
    "            cond = source_long[varname] < 0\n",
    "            if np.sum(cond) > 0:\n",
    "                source_long.loc[cond, varname] = np.nan\n",
    "\n",
    "    # Perform some basic consistency checks for the constructed panel.\n",
    "    def testing(self):\n",
    "      \n",
    "        # Distribute class attributes\n",
    "        source_long = self.source_long\n",
    "\n",
    "        # There are several variables where there cannot be a missing value.\n",
    "        varnames = []\n",
    "        varnames += ['IDENTIFIER', 'RACE', 'GENDER', 'MONTH_OF_BIRTH', 'YEAR_OF_BIRTH']\n",
    "        varnames += ['SURVEY_YEAR']\n",
    "        for varname in varnames:\n",
    "            np.testing.assert_equal(source_long[varname].notnull().all(), True)\n",
    "    \n",
    "        # The same is true for the all EMP_STATUS_ variables. In R26.1 there is one individual\n",
    "        # which in fact does have missing values in their employment status.\n",
    "        subset = source_long.drop(9269, level='Identifier')\n",
    "        np.testing.assert_equal(subset.filter(regex='EMP_STATUS_*').notnull().all().all(), True)\n",
    "        \n",
    "        # For all EMP_HOURS_ variables, we know that non-missing values need to be positive.\n",
    "        assert source_long.filter(regex='EMP_HOURS_*').apply(lambda column: (column[column.notnull()] >= 0).all()).all()\n",
    "    \n",
    "        # There are several variables which are not supposed to vary over time.\n",
    "        varnames = []\n",
    "        varnames += ['IDENTIFIER', 'RACE', 'GENDER', 'MONTH_OF_BIRTH', 'YEAR_OF_BIRTH', 'AFQT_1']\n",
    "        varnames += ['AFQT_RAW', 'ASVAB_ALTERED_TESTING', 'SAMPLE_ID']\n",
    "        for varname in varnames:\n",
    "            np.testing.assert_equal((source_long[varname].notnull().groupby(\n",
    "                level='Identifier').std() == 0).all(), True)\n",
    "\n",
    "        # The distribution of race is known from the NLSY website.\n",
    "        values = source_long['RACE'].loc[:, 1979].value_counts().values\n",
    "        np.testing.assert_almost_equal([7510, 3174, 2002], values)\n",
    "    \n",
    "        # The distribution of gender is known from the NLSY website.\n",
    "        values = source_long['GENDER'].loc[:, 1979].value_counts().values\n",
    "        np.testing.assert_almost_equal([6403, 6283], values)\n",
    "\n",
    "        # The distribution of sample identifiers is known from the NLSY website.\n",
    "        values = source_long['SAMPLE_ID'].loc[:, 1979].value_counts().values\n",
    "        np.testing.assert_almost_equal([2279, 2236, 1105, 1067, 901, 751, 742, 729, 609, 405,\n",
    "                                        346, 342, 226, 218, 203, 198, 162, 89, 53, 25], values)\n",
    "\n",
    "        # A bit about the AFQT_1 variable is known from the codebook.\n",
    "        stat = source_long['AFQT_1'].groupby(level='Identifier').first().isnull().sum()\n",
    "        np.testing.assert_equal(stat, 808)\n",
    "        stat = (source_long['AFQT_1'].min(), source_long['AFQT_1'].max())\n",
    "        np.testing.assert_equal(stat, (1, 99))\n",
    "        stat = source_long['AFQT_1'].mean()\n",
    "        np.testing.assert_equal(stat, 40.906044788684966)\n",
    "\n",
    "        # ASVAB_ALTERED_TESTING\n",
    "        values = source_long.groupby(level='Identifier').first()['ASVAB_ALTERED_TESTING'].value_counts().values\n",
    "        np.testing.assert_equal([11625, 127, 85, 41, 36], values)\n",
    "\n",
    "        # We know that CPSOCC70 is used to impute OCCALL70_MOD_JOB_1 in 1979 and 1993.\n",
    "        for year in [1979, 1993]:\n",
    "            cond = source_long['CPSOCC70'][:, year].equals(source_long['OCCALL70_MOD_JOB_1'][:, year])\n",
    "            np.testing.assert_equal(cond, True)\n",
    "\n",
    "        '''Check the distribution of selected variables at random.\n",
    "        '''\n",
    "        \n",
    "        # HIGHEST_DEGREE_RECEIVED\n",
    "        cases = []\n",
    "        cases += [(1988, (6031, 922, 626, 587, 178, 160, 49, 11))]\n",
    "        cases += [(1996, (60, 36, 29, 24, 10, 2, 1))]\n",
    "        cases += [(2010, (4025, 976, 728, 708, 442, 394, 178, 49, 47))]\n",
    "\n",
    "        for case in cases:\n",
    "            year, rslt = case\n",
    "            label = 'HIGHEST_DEGREE_RECEIVED'\n",
    "            np.testing.assert_equal(source_long[label][:, year].value_counts().values, rslt)\n",
    "\n",
    "        # HIGHEST_GRADE_ATTENDED\n",
    "        cases = []\n",
    "        cases += [(1984, (352, 212, 212, 201, 108, 61, 21, 15, 10, 10, 6, 4))]\n",
    "        cases += [(1994, (72, 61, 59, 34, 34, 33, 31, 17, 9, 7, 6, 5, 4, 1))]\n",
    "        cases += [(2002, (94, 64, 61, 51, 51, 37, 35, 22, 16, 9, 6, 4, 2, 1))]\n",
    "\n",
    "        for case in cases:\n",
    "            year, rslt = case\n",
    "            label = 'HIGHEST_GRADE_ATTENDED'\n",
    "            np.testing.assert_equal(source_long[label][:, year].value_counts().values, rslt)\n",
    "\n",
    "        # SCHOOL_ENROLLMENT MONTHLY\n",
    "        cases = []\n",
    "        cases += [(2011, 'JANUARY', '1', (188, 156))]\n",
    "        cases += [(1980, 'APRIL', '1', (5353,))]\n",
    "        cases += [(1994, 'JUNE', '1', (490, 232))]\n",
    "\n",
    "        for case in cases:\n",
    "            year, month, idx, rslt = case\n",
    "            label = 'ENROLLED_SCHOOL_' + month + '_' + idx\n",
    "            np.testing.assert_equal(source_long[label][:, year].value_counts().values, rslt)\n",
    "\n",
    "        # IS_INTERVIEWED\n",
    "        cases = []\n",
    "        cases += [(1980, (12141, 545))]\n",
    "        cases += [(1994, (8891, 3795))]\n",
    "        cases += [(2000, (8032, 4654))]\n",
    "\n",
    "        for case in cases:\n",
    "            year, rslt = case\n",
    "            stat = source_long['IS_INTERVIEWED'].groupby('Survey Year').value_counts()[year].values\n",
    "            np.testing.assert_equal(stat, rslt)\n",
    "\n",
    "        # CPSOCC70\n",
    "        cases = []\n",
    "        cases += [[(1979, source_long), (173, 104, 345, 1038, 403, 0, 785, 615, 9, 181, 1295, 253)]]\n",
    "        cases += [[(1988, source_long), (1356, 966, 415, 1825, 1016, 0, 1274, 617, 14, 113, 1271, 122)]]\n",
    "        cases += [[(1993, source_long), (1276, 909, 313, 1393,  857, 1,  942, 557, 24, 47, 1171, 60)]]\n",
    "\n",
    "        for case in cases:\n",
    "            args, rslt = case\n",
    "            np.testing.assert_almost_equal(rslt, cpsocc_counts(*args))\n",
    "\n",
    "        # OCCALL70\n",
    "        cases = []\n",
    "        cases += [[(1988, 1, source_long), (24, 6, 5, 15, 8, 0, 10, 9, 0, 2, 32, 2)]]\n",
    "        cases += [[(1993, 3, source_long), (43, 18, 16, 51, 35, 1, 47, 23, 1, 1, 68, 3)]]\n",
    "        cases += [[(2000, 5, source_long), (8, 8, 1, 7, 15, 0, 17, 8, 0, 1, 21, 0)]]\n",
    "\n",
    "        for case in cases:\n",
    "            args, rslt = case\n",
    "            np.testing.assert_almost_equal(rslt, occall_counts(*args))\n",
    "\n",
    "        # EMP_STATUS\n",
    "        cases = []\n",
    "        cases += [[(2007, 26, source_long), (6240, 4614, 38, 0, 321, 1464, 9)]]\n",
    "        cases += [[(1997, 46, source_long), (7206, 3668, 16, 0, 258, 1464, 73)]]\n",
    "        cases += [[(1987, 20, source_long), (8068, 1486, 65, 43, 554, 2171, 299)]]\n",
    "\n",
    "        for case in cases:\n",
    "            args, rslt = case\n",
    "            np.testing.assert_almost_equal(rslt, emp_status_counts(*args))\n",
    "\n",
    "        # EMP_HOURS\n",
    "        cases = []\n",
    "        cases += [[(1992, 14, source_long), (5697, 87, 194, 330, 762, 4009, 876, 379, 151, 74, 78, 0, 49)]]\n",
    "        cases += [[(2009, 7, source_long), (6760, 79, 144, 280, 664, 3350, 707, 375, 147, 83, 23, 33, 41)]]\n",
    "        cases += [[(2010, 52, source_long), (7170, 68, 111, 278, 558, 3061, 766, 356, 144, 68, 17, 44, 45)]]\n",
    "\n",
    "        for case in cases:\n",
    "            args, rslt = case\n",
    "            np.testing.assert_almost_equal(rslt, emp_hours_counts(*args))\n",
    "\n",
    "        # WAGE_HOURLY\n",
    "        cases = []\n",
    "        cases += [[(1979, 5, source_long), (0, 3, 6, 45, 26, 8, 1, 3, 0, 1, 0, 1)]]\n",
    "        cases += [[(1988, 4, source_long), (0, 2, 2, 6, 59, 76, 67, 53, 42, 15, 10, 52)]]\n",
    "        cases += [[(1991, 2, source_long), (0, 26, 44, 41, 97, 323, 327, 262, 180, 182, 119, 647)]]\n",
    "\n",
    "        for case in cases:\n",
    "            args, rslt = case\n",
    "            np.testing.assert_almost_equal(rslt, wage_hourly_counts(*args))\n",
    "\n",
    "        # Confirm that all included variables are mentioned at the beginning of the notebook.\n",
    "        varnames = TIME_CONSTANT + TIME_VARYING + DERIVED_VARS\n",
    "        np.testing.assert_equal(set(source_long.columns.values), set(varnames))\n",
    "\n",
    "        # This ensures that there are no surprising changes to the dataset\n",
    "        val = 8726642399.5\n",
    "        np.testing.assert_equal(source_long.sum(numeric_only=True).sum(), val)\n",
    "\n",
    "    # Store the dataset for further proccessing\n",
    "    def store(self, fname):\n",
    "\n",
    "        # Distribute class attributes\n",
    "        source_long = self.source_long\n",
    "\n",
    "        # Write out persistent storage\n",
    "        source_long.to_pickle(fname)\n",
    "\n",
    "    # Store the dataset for further processing.\n",
    "    def load(self, fname):\n",
    "\n",
    "        # Distribute class attributes\n",
    "        self.source_long = pd.read_pickle(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original data is set up in wide format; the following allows for working with a typical panel structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_to_long(source_wide, additional_level, dct):\n",
    "\n",
    "    # Set up an empty dataframe with the right index structure. This setup maintains the mapping\n",
    "    # between the index in the dataframe and the NLSY identifier.\n",
    "    caseid = [x + 1 for x in source_wide.index]\n",
    "    multi_index = pd.MultiIndex.from_product([caseid, additional_level], names=['Identifier', 'Survey Year'])\n",
    "    pd_long = pd.DataFrame(index=multi_index)\n",
    "\n",
    "    # It is useful to have a column that corresponds to each of the two indices.\n",
    "    pd_long['IDENTIFIER'] = pd_long.index.get_level_values('Identifier')\n",
    "    pd_long['SURVEY_YEAR'] = pd_long.index.get_level_values('Survey Year')\n",
    "\n",
    "    for long_name in dct.keys():\n",
    "        # Initialize the column with missing values.\n",
    "        pd_long[long_name] = np.nan\n",
    "        for year in additional_level:\n",
    "            # Some variables might not be defined for each year. If that is the case,\n",
    "            # missing values simply remain.\n",
    "            if year not in dct[long_name].keys():\n",
    "                continue\n",
    "            # Now simply assign the variable name to the corresponding year.\n",
    "            pd_long.loc[(slice(None), year), long_name] = source_wide[dct[long_name][year]].values\n",
    "\n",
    "    # Some variables have no missing values and so integer type can be imposed.\n",
    "    for varname in ['IDENTIFIER', 'SURVEY_YEAR', 'RACE', 'GENDER']:\n",
    "        pd_long[varname] = pd_long[varname].astype('int64')\n",
    "\n",
    "    return pd_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns counts for each of the bins of the variable.\n",
    "def cpsocc_counts(year, source_long):\n",
    "\n",
    "    bins = []\n",
    "    bins += [(1, 195), (201, 245), (260, 285), (301, 395), (401, 575), (580, 590)]\n",
    "    bins += [(601, 715), (740, 785), (801, 802), (821, 824), (901, 965), (980, 984)]\n",
    "\n",
    "    counts = _get_counts_year(source_long['CPSOCC70'], bins, year)\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns counts for each of the bins of the variable.\n",
    "def occall_counts(year, num, source_long):\n",
    "\n",
    "    bins = []\n",
    "    bins += [(1, 195), (201, 245), (260, 285), (301, 395), (401, 575), (580, 590), (601, 715)]\n",
    "    bins += [(740, 785), (801, 802), (821, 824), (901, 965), (980, 984)]\n",
    "\n",
    "    counts = _get_counts_year(source_long['OCCALL70_JOB_' + str(num)], bins, year)\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns counts for each of the bins of the variable.\n",
    "def wage_hourly_counts(year, num, source_long):\n",
    "\n",
    "    bins = []\n",
    "    bins += [(0, 1), (1, 99), (100, 199), (200, 299), (300, 399), (400, 499), (500, 599)]\n",
    "    bins += [(600, 699), (700, 799), (800, 899), (900, 999), (1000, np.inf)]\n",
    "\n",
    "    counts = _get_counts_year(source_long['WAGE_HOURLY_JOB_' + str(num)], bins, year)\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns counts for each of the bins of the variable.\n",
    "def emp_hours_counts(year, week, source_long):\n",
    "\n",
    "    bins = []\n",
    "    bins += [(0, 0), (1, 9), (10, 19), (20, 29), (30, 39), (40, 49), (50, 59), (60, 69)]\n",
    "    bins += [(70, 79), (80, 89), (90, 99), (100, np.inf)]\n",
    "\n",
    "    label = 'EMP_HOURS_WK_' + str(week)\n",
    "    counts = _get_counts_year(source_long[label], bins, year)\n",
    "    counts += [source_long[label].loc[:, year].isnull().sum()]\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns counts for each of the bins of the variable.\n",
    "def emp_status_counts(year, week, source_long):\n",
    "\n",
    "    bins = []\n",
    "    bins += [(100, np.inf), (0, 0), (2, 2), (3, 3), (4, 4), (5, 5), (7, 7)]\n",
    "\n",
    "    counts = _get_counts_year(source_long['EMP_STATUS_WK_' + str(week)], bins, year)\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns counts for each of the bins of the variable.\n",
    "def _get_counts_year(series, bins, year):\n",
    "    \n",
    "    counts = []\n",
    "    for bounds in bins:\n",
    "        lower, upper = bounds\n",
    "        counts += [series.loc[:, year].between(lower, upper).sum()]\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'R0214700'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Desktop\\repos\\gorman-earlyjobskill-analysis\\env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3081\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3082\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'R0214700'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-071602395946>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msource_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_source\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0msource_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_wide_to_panel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0msource_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_basic_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0msource_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-74f332e99c75>\u001b[0m in \u001b[0;36mtransform_wide_to_panel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m# Change from the original wide format to the typical panel structure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource_long\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwide_to_long\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_wide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msurvey_years\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_missing_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-53d6e090cc88>\u001b[0m in \u001b[0;36mwide_to_long\u001b[1;34m(source_wide, additional_level, dct)\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m# Now simply assign the variable name to the corresponding year.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mpd_long\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlong_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource_wide\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdct\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlong_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Some variables have no missing values and so integer type can be imposed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\repos\\gorman-earlyjobskill-analysis\\env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\repos\\gorman-earlyjobskill-analysis\\env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3081\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3083\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'R0214700'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    fname = r'C:\\Users\\15853\\Desktop\\repos\\gorman-earlyjobskill-analysis\\data\\output\\full-list-variables.pkl'\n",
    "\n",
    "    source_obj = SourceCls()\n",
    "\n",
    "    source_obj.read_source()\n",
    "    source_obj.transform_wide_to_panel()\n",
    "    source_obj.add_basic_variables()\n",
    "    source_obj.store(fname)\n",
    "\n",
    "    source_obj.load(fname)\n",
    "    source_obj.testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
